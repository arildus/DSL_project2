{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import helpers.processing_helpers as ph\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/development.csv\")\n",
    "\n",
    "noise_indexes = [0,7,12,15,16,17]\n",
    "\n",
    "\n",
    "\n",
    "features = ['pmax', 'negpmax', 'area', 'tmax', 'rms']\n",
    "\n",
    "drop_features = ['area', 'tmax', 'rms']\n",
    "\n",
    "df = df.drop(columns=ph.get_column_names(features, noise_indexes)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_feature_reduction(df: pd.DataFrame):\n",
    "    \n",
    "    feature_to_loss = {}\n",
    "    drop_features_list = [('area',), ('tmax',), ('rms',), ('area', 'tmax'), ('area', 'rms'), ('rms', 'tmax'), ('area', 'tmax', 'rms')]\n",
    "    acc_idxs = [1,2,3,4,5,6,8,9,10,11,13,14]\n",
    "\n",
    "    for drop_features in drop_features_list:\n",
    "        \n",
    "        df_dev = df.drop(columns=ph.get_column_names(drop_features, acc_idxs))\n",
    "        y_train_valid = df_dev[['x', 'y']].copy()\n",
    "\n",
    "        X_train_valid = df_dev.drop(columns=['x', 'y'])\n",
    "\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, shuffle=True)\n",
    "\n",
    "        means = X_train.mean()\n",
    "        stds = X_train.std()\n",
    "\n",
    "        X_train_normalized = (X_train - means) / stds\n",
    "\n",
    "        X_valid_normalized = (X_valid - means) / stds\n",
    "\n",
    "        mlp = MLPRegressor(random_state=42, verbose=1, n_iter_no_change=500, max_iter=100, learning_rate_init=0.01, activation=\"logistic\", learning_rate=\"adaptive\")\n",
    "        mlp.fit(X_train_normalized, y_train)\n",
    "\n",
    "        y_pred = mlp.predict(X_valid_normalized)\n",
    "\n",
    "        result = (ph.mean_euclid_dist(y_valid, y_pred))\n",
    "        feature_to_loss[drop_features] = result\n",
    "    return feature_to_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 13537.75947061\n",
      "Iteration 2, loss = 888.22991078\n",
      "Iteration 3, loss = 117.24240615\n",
      "Iteration 4, loss = 35.31888956\n",
      "Iteration 5, loss = 21.70328892\n",
      "Iteration 6, loss = 17.39044158\n",
      "Iteration 7, loss = 15.09834849\n",
      "Iteration 8, loss = 13.73975474\n",
      "Iteration 9, loss = 12.88917924\n",
      "Iteration 10, loss = 12.20596193\n",
      "Iteration 11, loss = 11.82781507\n",
      "Iteration 12, loss = 11.73215550\n",
      "Iteration 13, loss = 11.45227981\n",
      "Iteration 14, loss = 11.34841722\n",
      "Iteration 15, loss = 11.20070123\n",
      "Iteration 16, loss = 11.05743879\n",
      "Iteration 17, loss = 10.98085114\n",
      "Iteration 18, loss = 10.95930083\n",
      "Iteration 19, loss = 10.92524564\n",
      "Iteration 20, loss = 10.77958054\n",
      "Iteration 21, loss = 10.72592638\n",
      "Iteration 22, loss = 10.71419799\n",
      "Iteration 23, loss = 10.58348023\n",
      "Iteration 24, loss = 10.51718586\n",
      "Iteration 25, loss = 10.52278397\n",
      "Iteration 26, loss = 10.48441766\n",
      "Iteration 27, loss = 10.44388416\n",
      "Iteration 28, loss = 10.46356541\n",
      "Iteration 29, loss = 10.47131998\n",
      "Iteration 30, loss = 10.40083455\n",
      "Iteration 31, loss = 10.42513164\n",
      "Iteration 32, loss = 10.34432196\n",
      "Iteration 33, loss = 10.33944695\n",
      "Iteration 34, loss = 10.25802024\n",
      "Iteration 35, loss = 10.33275857\n",
      "Iteration 36, loss = 10.25912636\n",
      "Iteration 37, loss = 10.26992784\n",
      "Iteration 38, loss = 10.22535785\n",
      "Iteration 39, loss = 10.25256508\n",
      "Iteration 40, loss = 10.17906199\n",
      "Iteration 41, loss = 10.19860895\n",
      "Iteration 42, loss = 10.22507244\n",
      "Iteration 43, loss = 10.17608587\n",
      "Iteration 44, loss = 10.18569901\n",
      "Iteration 45, loss = 10.24570293\n",
      "Iteration 46, loss = 10.20978576\n",
      "Iteration 47, loss = 10.20309019\n",
      "Iteration 48, loss = 10.18150926\n",
      "Iteration 49, loss = 10.13278512\n",
      "Iteration 50, loss = 10.17313944\n",
      "Iteration 51, loss = 10.11289246\n",
      "Iteration 52, loss = 10.08618174\n",
      "Iteration 53, loss = 10.12548317\n",
      "Iteration 54, loss = 10.06631913\n",
      "Iteration 55, loss = 10.12865703\n",
      "Iteration 56, loss = 10.03868847\n",
      "Iteration 57, loss = 10.02709104\n",
      "Iteration 58, loss = 10.02587300\n",
      "Iteration 59, loss = 9.98681548\n",
      "Iteration 60, loss = 10.04067764\n",
      "Iteration 61, loss = 10.00646003\n",
      "Iteration 62, loss = 9.99635793\n",
      "Iteration 63, loss = 9.92919431\n",
      "Iteration 64, loss = 10.04945151\n",
      "Iteration 65, loss = 10.03192915\n",
      "Iteration 66, loss = 9.98407656\n",
      "Iteration 67, loss = 10.01190618\n",
      "Iteration 68, loss = 9.94337503\n",
      "Iteration 69, loss = 9.93709962\n",
      "Iteration 70, loss = 9.92590094\n",
      "Iteration 71, loss = 9.97834437\n",
      "Iteration 72, loss = 9.86802555\n",
      "Iteration 73, loss = 9.95651244\n",
      "Iteration 74, loss = 9.97082027\n",
      "Iteration 75, loss = 9.94799929\n",
      "Iteration 76, loss = 9.92323681\n",
      "Iteration 77, loss = 9.88113614\n",
      "Iteration 78, loss = 9.89809388\n",
      "Iteration 79, loss = 9.88381726\n",
      "Iteration 80, loss = 9.89123423\n",
      "Iteration 81, loss = 9.82506069\n",
      "Iteration 82, loss = 9.84833622\n",
      "Iteration 83, loss = 9.83967837\n",
      "Iteration 84, loss = 9.82394974\n",
      "Iteration 85, loss = 9.81056674\n",
      "Iteration 86, loss = 9.85503113\n",
      "Iteration 87, loss = 9.88484718\n",
      "Iteration 88, loss = 9.84846010\n",
      "Iteration 89, loss = 9.83087282\n",
      "Iteration 90, loss = 9.82763635\n",
      "Iteration 91, loss = 9.84347382\n",
      "Iteration 92, loss = 9.80109583\n",
      "Iteration 93, loss = 9.79527937\n",
      "Iteration 94, loss = 9.76019939\n",
      "Iteration 95, loss = 9.81259389\n",
      "Iteration 96, loss = 9.78337616\n",
      "Iteration 97, loss = 9.74868432\n",
      "Iteration 98, loss = 9.70802217\n",
      "Iteration 99, loss = 9.67910872\n",
      "Iteration 100, loss = 9.73987452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 13400.72949000\n",
      "Iteration 2, loss = 832.71508264\n",
      "Iteration 3, loss = 116.29342713\n",
      "Iteration 4, loss = 37.07159113\n",
      "Iteration 5, loss = 22.25388377\n",
      "Iteration 6, loss = 17.15182781\n",
      "Iteration 7, loss = 14.73578206\n",
      "Iteration 8, loss = 13.31492971\n",
      "Iteration 9, loss = 12.41543918\n",
      "Iteration 10, loss = 11.74685443\n",
      "Iteration 11, loss = 11.27750748\n",
      "Iteration 12, loss = 10.96715916\n",
      "Iteration 13, loss = 10.74482125\n",
      "Iteration 14, loss = 10.62695102\n",
      "Iteration 15, loss = 10.45366404\n",
      "Iteration 16, loss = 10.36279427\n",
      "Iteration 17, loss = 10.39045600\n",
      "Iteration 18, loss = 10.25917738\n",
      "Iteration 19, loss = 10.16699898\n",
      "Iteration 20, loss = 10.09415279\n",
      "Iteration 21, loss = 9.99141398\n",
      "Iteration 22, loss = 9.96678237\n",
      "Iteration 23, loss = 9.94111132\n",
      "Iteration 24, loss = 9.83021790\n",
      "Iteration 25, loss = 9.91693461\n",
      "Iteration 26, loss = 9.76922666\n",
      "Iteration 27, loss = 9.81567446\n",
      "Iteration 28, loss = 9.68938546\n",
      "Iteration 29, loss = 9.65799850\n",
      "Iteration 30, loss = 9.64466890\n",
      "Iteration 31, loss = 9.60368617\n",
      "Iteration 32, loss = 9.59951874\n",
      "Iteration 33, loss = 9.59744542\n",
      "Iteration 34, loss = 9.59667325\n",
      "Iteration 35, loss = 9.55528481\n",
      "Iteration 36, loss = 9.56600474\n",
      "Iteration 37, loss = 9.55336451\n",
      "Iteration 38, loss = 9.54201130\n",
      "Iteration 39, loss = 9.54173152\n",
      "Iteration 40, loss = 9.43768819\n",
      "Iteration 41, loss = 9.43242260\n",
      "Iteration 42, loss = 9.39371105\n",
      "Iteration 43, loss = 9.39679405\n",
      "Iteration 44, loss = 9.40731524\n",
      "Iteration 45, loss = 9.37932149\n",
      "Iteration 46, loss = 9.43934071\n",
      "Iteration 47, loss = 9.35479047\n",
      "Iteration 48, loss = 9.34721896\n",
      "Iteration 49, loss = 9.39495449\n",
      "Iteration 50, loss = 9.31991448\n",
      "Iteration 51, loss = 9.35137113\n",
      "Iteration 52, loss = 9.37520376\n",
      "Iteration 53, loss = 9.28372714\n",
      "Iteration 54, loss = 9.34662321\n",
      "Iteration 55, loss = 9.28260774\n",
      "Iteration 56, loss = 9.32298994\n",
      "Iteration 57, loss = 9.28770241\n",
      "Iteration 58, loss = 9.26186100\n",
      "Iteration 59, loss = 9.26585947\n",
      "Iteration 60, loss = 9.30688422\n",
      "Iteration 61, loss = 9.29185549\n",
      "Iteration 62, loss = 9.20206829\n",
      "Iteration 63, loss = 9.21929274\n",
      "Iteration 64, loss = 9.19363756\n",
      "Iteration 65, loss = 9.29286350\n",
      "Iteration 66, loss = 9.22639443\n",
      "Iteration 67, loss = 9.22844225\n",
      "Iteration 68, loss = 9.23952767\n",
      "Iteration 69, loss = 9.24103934\n",
      "Iteration 70, loss = 9.28350276\n",
      "Iteration 71, loss = 9.19072782\n",
      "Iteration 72, loss = 9.25474672\n",
      "Iteration 73, loss = 9.18971920\n",
      "Iteration 74, loss = 9.17774587\n",
      "Iteration 75, loss = 9.17525921\n",
      "Iteration 76, loss = 9.25542903\n",
      "Iteration 77, loss = 9.18607236\n",
      "Iteration 78, loss = 9.15101570\n",
      "Iteration 79, loss = 9.18449796\n",
      "Iteration 80, loss = 9.16318057\n",
      "Iteration 81, loss = 9.14535659\n",
      "Iteration 82, loss = 9.15674106\n",
      "Iteration 83, loss = 9.17921491\n",
      "Iteration 84, loss = 9.17812548\n",
      "Iteration 85, loss = 9.17388258\n",
      "Iteration 86, loss = 9.12349018\n",
      "Iteration 87, loss = 9.17410764\n",
      "Iteration 88, loss = 9.13485586\n",
      "Iteration 89, loss = 9.13678793\n",
      "Iteration 90, loss = 9.11230272\n",
      "Iteration 91, loss = 9.10590674\n",
      "Iteration 92, loss = 9.12737610\n",
      "Iteration 93, loss = 9.09190031\n",
      "Iteration 94, loss = 9.09486340\n",
      "Iteration 95, loss = 9.05757875\n",
      "Iteration 96, loss = 9.09626582\n",
      "Iteration 97, loss = 9.12179511\n",
      "Iteration 98, loss = 9.06210485\n",
      "Iteration 99, loss = 9.05394542\n",
      "Iteration 100, loss = 9.00518800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 13434.80413616\n",
      "Iteration 2, loss = 844.40580423\n",
      "Iteration 3, loss = 117.06756726\n",
      "Iteration 4, loss = 36.86647175\n",
      "Iteration 5, loss = 22.13489106\n",
      "Iteration 6, loss = 17.19413382\n",
      "Iteration 7, loss = 14.77457273\n",
      "Iteration 8, loss = 13.35507712\n",
      "Iteration 9, loss = 12.45853751\n",
      "Iteration 10, loss = 11.89547539\n",
      "Iteration 11, loss = 11.51342146\n",
      "Iteration 12, loss = 11.18137693\n",
      "Iteration 13, loss = 10.93676688\n",
      "Iteration 14, loss = 10.71970733\n",
      "Iteration 15, loss = 10.66003941\n",
      "Iteration 16, loss = 10.49077335\n",
      "Iteration 17, loss = 10.34699816\n",
      "Iteration 18, loss = 10.25896885\n",
      "Iteration 19, loss = 10.20875832\n",
      "Iteration 20, loss = 10.19702634\n",
      "Iteration 21, loss = 10.14197971\n",
      "Iteration 22, loss = 9.97134001\n",
      "Iteration 23, loss = 10.00591688\n",
      "Iteration 24, loss = 9.96316499\n",
      "Iteration 25, loss = 9.84398211\n",
      "Iteration 26, loss = 9.86237665\n",
      "Iteration 27, loss = 9.81745620\n",
      "Iteration 28, loss = 9.88110274\n",
      "Iteration 29, loss = 9.80741088\n",
      "Iteration 30, loss = 9.73910966\n",
      "Iteration 31, loss = 9.76751426\n",
      "Iteration 32, loss = 9.70846102\n",
      "Iteration 33, loss = 9.65856938\n",
      "Iteration 34, loss = 9.69221724\n",
      "Iteration 35, loss = 9.71629327\n",
      "Iteration 36, loss = 9.67920034\n",
      "Iteration 37, loss = 9.68685560\n",
      "Iteration 38, loss = 9.71364045\n",
      "Iteration 39, loss = 9.67448419\n",
      "Iteration 40, loss = 9.58460788\n",
      "Iteration 41, loss = 9.66259893\n",
      "Iteration 42, loss = 9.60946456\n",
      "Iteration 43, loss = 9.64132197\n",
      "Iteration 44, loss = 9.53853714\n",
      "Iteration 45, loss = 9.57728380\n",
      "Iteration 46, loss = 9.59386245\n",
      "Iteration 47, loss = 9.48879288\n",
      "Iteration 48, loss = 9.55871117\n",
      "Iteration 49, loss = 9.54597533\n",
      "Iteration 50, loss = 9.48137192\n",
      "Iteration 51, loss = 9.54529140\n",
      "Iteration 52, loss = 9.52052544\n",
      "Iteration 53, loss = 9.51200104\n",
      "Iteration 54, loss = 9.48096369\n",
      "Iteration 55, loss = 9.44765816\n",
      "Iteration 56, loss = 9.48440255\n",
      "Iteration 57, loss = 9.52051141\n",
      "Iteration 58, loss = 9.50440336\n",
      "Iteration 59, loss = 9.49198927\n",
      "Iteration 60, loss = 9.47302194\n",
      "Iteration 61, loss = 9.45505819\n",
      "Iteration 62, loss = 9.44053925\n",
      "Iteration 63, loss = 9.37378212\n",
      "Iteration 64, loss = 9.47186577\n",
      "Iteration 65, loss = 9.44432354\n",
      "Iteration 66, loss = 9.45613279\n",
      "Iteration 67, loss = 9.37938006\n",
      "Iteration 68, loss = 9.41332110\n",
      "Iteration 69, loss = 9.49734175\n",
      "Iteration 70, loss = 9.44282541\n",
      "Iteration 71, loss = 9.36700847\n",
      "Iteration 72, loss = 9.36456717\n",
      "Iteration 73, loss = 9.41365961\n",
      "Iteration 74, loss = 9.38416875\n",
      "Iteration 75, loss = 9.35702701\n",
      "Iteration 76, loss = 9.33597952\n",
      "Iteration 77, loss = 9.32134483\n",
      "Iteration 78, loss = 9.33012213\n",
      "Iteration 79, loss = 9.30127789\n",
      "Iteration 80, loss = 9.28778894\n",
      "Iteration 81, loss = 9.30603203\n",
      "Iteration 82, loss = 9.36177890\n",
      "Iteration 83, loss = 9.31831578\n",
      "Iteration 84, loss = 9.28073058\n",
      "Iteration 85, loss = 9.38659451\n",
      "Iteration 86, loss = 9.30179185\n",
      "Iteration 87, loss = 9.27815985\n",
      "Iteration 88, loss = 9.32577092\n",
      "Iteration 89, loss = 9.26352795\n",
      "Iteration 90, loss = 9.31118882\n",
      "Iteration 91, loss = 9.32408986\n",
      "Iteration 92, loss = 9.33336080\n",
      "Iteration 93, loss = 9.24114900\n",
      "Iteration 94, loss = 9.29208525\n",
      "Iteration 95, loss = 9.24892232\n",
      "Iteration 96, loss = 9.30269898\n",
      "Iteration 97, loss = 9.27133776\n",
      "Iteration 98, loss = 9.24381655\n",
      "Iteration 99, loss = 9.21975646\n",
      "Iteration 100, loss = 9.22706697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 13330.80227120\n",
      "Iteration 2, loss = 876.80813419\n",
      "Iteration 3, loss = 116.85266940\n",
      "Iteration 4, loss = 35.62263640\n",
      "Iteration 5, loss = 21.45309393\n",
      "Iteration 6, loss = 16.89400604\n",
      "Iteration 7, loss = 14.50129148\n",
      "Iteration 8, loss = 12.99143541\n",
      "Iteration 9, loss = 12.01925256\n",
      "Iteration 10, loss = 11.50177126\n",
      "Iteration 11, loss = 11.09619246\n",
      "Iteration 12, loss = 10.81957710\n",
      "Iteration 13, loss = 10.60769668\n",
      "Iteration 14, loss = 10.45566333\n",
      "Iteration 15, loss = 10.29129976\n",
      "Iteration 16, loss = 10.24714445\n",
      "Iteration 17, loss = 10.15110813\n",
      "Iteration 18, loss = 10.13871236\n",
      "Iteration 19, loss = 10.06466002\n",
      "Iteration 20, loss = 9.95050717\n",
      "Iteration 21, loss = 9.90934046\n",
      "Iteration 22, loss = 9.77769644\n",
      "Iteration 23, loss = 9.77852294\n",
      "Iteration 24, loss = 9.69565105\n",
      "Iteration 25, loss = 9.72395607\n",
      "Iteration 26, loss = 9.65423581\n",
      "Iteration 27, loss = 9.65951102\n",
      "Iteration 28, loss = 9.64248939\n",
      "Iteration 29, loss = 9.59047511\n",
      "Iteration 30, loss = 9.56429176\n",
      "Iteration 31, loss = 9.51119109\n",
      "Iteration 32, loss = 9.44918137\n",
      "Iteration 33, loss = 9.52562015\n",
      "Iteration 34, loss = 9.51545260\n",
      "Iteration 35, loss = 9.51094814\n",
      "Iteration 36, loss = 9.47733358\n",
      "Iteration 37, loss = 9.46177135\n",
      "Iteration 38, loss = 9.41660868\n",
      "Iteration 39, loss = 9.40320070\n",
      "Iteration 40, loss = 9.37588231\n",
      "Iteration 41, loss = 9.40653349\n",
      "Iteration 42, loss = 9.39328071\n",
      "Iteration 43, loss = 9.36460924\n",
      "Iteration 44, loss = 9.31280800\n",
      "Iteration 45, loss = 9.29342787\n",
      "Iteration 46, loss = 9.32513111\n",
      "Iteration 47, loss = 9.35551233\n",
      "Iteration 48, loss = 9.27971399\n",
      "Iteration 49, loss = 9.29003012\n",
      "Iteration 50, loss = 9.29946294\n",
      "Iteration 51, loss = 9.29254603\n",
      "Iteration 52, loss = 9.23916308\n",
      "Iteration 53, loss = 9.25827900\n",
      "Iteration 54, loss = 9.29877314\n",
      "Iteration 55, loss = 9.27052642\n",
      "Iteration 56, loss = 9.24409389\n",
      "Iteration 57, loss = 9.24699488\n",
      "Iteration 58, loss = 9.22684915\n",
      "Iteration 59, loss = 9.22600622\n",
      "Iteration 60, loss = 9.17777619\n",
      "Iteration 61, loss = 9.17388211\n",
      "Iteration 62, loss = 9.20167207\n",
      "Iteration 63, loss = 9.24036118\n",
      "Iteration 64, loss = 9.19666109\n",
      "Iteration 65, loss = 9.14452034\n",
      "Iteration 66, loss = 9.18919928\n",
      "Iteration 67, loss = 9.14491795\n",
      "Iteration 68, loss = 9.16895454\n",
      "Iteration 69, loss = 9.15349189\n",
      "Iteration 70, loss = 9.19937521\n",
      "Iteration 71, loss = 9.15655909\n",
      "Iteration 72, loss = 9.14769574\n",
      "Iteration 73, loss = 9.14193504\n",
      "Iteration 74, loss = 9.12973912\n",
      "Iteration 75, loss = 9.07147125\n",
      "Iteration 76, loss = 9.10253239\n",
      "Iteration 77, loss = 9.13157184\n",
      "Iteration 78, loss = 9.07620375\n",
      "Iteration 79, loss = 9.07393101\n",
      "Iteration 80, loss = 9.09529101\n",
      "Iteration 81, loss = 9.12013235\n",
      "Iteration 82, loss = 9.07314116\n",
      "Iteration 83, loss = 9.13451442\n",
      "Iteration 84, loss = 9.09230107\n",
      "Iteration 85, loss = 9.17190167\n",
      "Iteration 86, loss = 9.09840645\n",
      "Iteration 87, loss = 9.08919526\n",
      "Iteration 88, loss = 9.08851341\n",
      "Iteration 89, loss = 9.01474151\n",
      "Iteration 90, loss = 9.02811685\n",
      "Iteration 91, loss = 9.07724733\n",
      "Iteration 92, loss = 9.04276091\n",
      "Iteration 93, loss = 9.08222946\n",
      "Iteration 94, loss = 9.01579175\n",
      "Iteration 95, loss = 9.04991988\n",
      "Iteration 96, loss = 9.07760388\n",
      "Iteration 97, loss = 9.02023858\n",
      "Iteration 98, loss = 8.98344667\n",
      "Iteration 99, loss = 8.98972607\n",
      "Iteration 100, loss = 8.97150910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 13484.71792897\n",
      "Iteration 2, loss = 887.51720797\n",
      "Iteration 3, loss = 117.34693773\n",
      "Iteration 4, loss = 35.89773582\n",
      "Iteration 5, loss = 21.97673281\n",
      "Iteration 6, loss = 17.40778942\n",
      "Iteration 7, loss = 14.95373202\n",
      "Iteration 8, loss = 13.52155341\n",
      "Iteration 9, loss = 12.63344555\n",
      "Iteration 10, loss = 12.09477901\n",
      "Iteration 11, loss = 11.62731528\n",
      "Iteration 12, loss = 11.30785508\n",
      "Iteration 13, loss = 11.14135014\n",
      "Iteration 14, loss = 10.92423974\n",
      "Iteration 15, loss = 10.82226989\n",
      "Iteration 16, loss = 10.62995147\n",
      "Iteration 17, loss = 10.51853862\n",
      "Iteration 18, loss = 10.37798185\n",
      "Iteration 19, loss = 10.35766718\n",
      "Iteration 20, loss = 10.33218843\n",
      "Iteration 21, loss = 10.32039455\n",
      "Iteration 22, loss = 10.18604509\n",
      "Iteration 23, loss = 10.15594242\n",
      "Iteration 24, loss = 10.16306009\n",
      "Iteration 25, loss = 10.04588071\n",
      "Iteration 26, loss = 9.99863405\n",
      "Iteration 27, loss = 9.96792003\n",
      "Iteration 28, loss = 9.94055384\n",
      "Iteration 29, loss = 9.83664085\n",
      "Iteration 30, loss = 9.83300735\n",
      "Iteration 31, loss = 9.79360446\n",
      "Iteration 32, loss = 9.75674854\n",
      "Iteration 33, loss = 9.72429589\n",
      "Iteration 34, loss = 9.67557994\n",
      "Iteration 35, loss = 9.64399938\n",
      "Iteration 36, loss = 9.61236240\n",
      "Iteration 37, loss = 9.60835325\n",
      "Iteration 38, loss = 9.59301685\n",
      "Iteration 39, loss = 9.54089871\n",
      "Iteration 40, loss = 9.51541724\n",
      "Iteration 41, loss = 9.59651436\n",
      "Iteration 42, loss = 9.49119069\n",
      "Iteration 43, loss = 9.45273765\n",
      "Iteration 44, loss = 9.49127552\n",
      "Iteration 45, loss = 9.49305440\n",
      "Iteration 46, loss = 9.46278311\n",
      "Iteration 47, loss = 9.42596055\n",
      "Iteration 48, loss = 9.39611732\n",
      "Iteration 49, loss = 9.38416899\n",
      "Iteration 50, loss = 9.40374159\n",
      "Iteration 51, loss = 9.42694880\n",
      "Iteration 52, loss = 9.35749923\n",
      "Iteration 53, loss = 9.35622641\n",
      "Iteration 54, loss = 9.33174120\n",
      "Iteration 55, loss = 9.35016332\n",
      "Iteration 56, loss = 9.28779015\n",
      "Iteration 57, loss = 9.32971656\n",
      "Iteration 58, loss = 9.30432803\n",
      "Iteration 59, loss = 9.27122526\n",
      "Iteration 60, loss = 9.26611186\n",
      "Iteration 61, loss = 9.25068273\n",
      "Iteration 62, loss = 9.22935903\n",
      "Iteration 63, loss = 9.18129067\n",
      "Iteration 64, loss = 9.29334359\n",
      "Iteration 65, loss = 9.25885326\n",
      "Iteration 66, loss = 9.29670427\n",
      "Iteration 67, loss = 9.24008945\n",
      "Iteration 68, loss = 9.24317859\n",
      "Iteration 69, loss = 9.14669760\n",
      "Iteration 70, loss = 9.20441354\n",
      "Iteration 71, loss = 9.09270465\n",
      "Iteration 72, loss = 9.15204411\n",
      "Iteration 73, loss = 9.19321646\n",
      "Iteration 74, loss = 9.12797054\n",
      "Iteration 75, loss = 9.17377027\n",
      "Iteration 76, loss = 9.10730792\n",
      "Iteration 77, loss = 9.10918408\n",
      "Iteration 78, loss = 9.06142675\n",
      "Iteration 79, loss = 9.05123529\n",
      "Iteration 80, loss = 9.01966561\n",
      "Iteration 81, loss = 9.11474727\n",
      "Iteration 82, loss = 9.08708876\n",
      "Iteration 83, loss = 9.06768096\n",
      "Iteration 84, loss = 9.07870985\n",
      "Iteration 85, loss = 9.09805854\n",
      "Iteration 86, loss = 9.13902180\n",
      "Iteration 87, loss = 9.09128399\n",
      "Iteration 88, loss = 8.99052998\n",
      "Iteration 89, loss = 9.03768884\n",
      "Iteration 90, loss = 9.03526552\n",
      "Iteration 91, loss = 9.04558970\n",
      "Iteration 92, loss = 9.05679183\n",
      "Iteration 93, loss = 9.03349468\n",
      "Iteration 94, loss = 9.12204026\n",
      "Iteration 95, loss = 9.00353043\n",
      "Iteration 96, loss = 9.00073300\n",
      "Iteration 97, loss = 8.98734853\n",
      "Iteration 98, loss = 8.92357951\n",
      "Iteration 99, loss = 8.95441993\n",
      "Iteration 100, loss = 9.01148026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 13354.57938972\n",
      "Iteration 2, loss = 839.13772878\n",
      "Iteration 3, loss = 116.49190162\n",
      "Iteration 4, loss = 36.63688791\n",
      "Iteration 5, loss = 22.12628482\n",
      "Iteration 6, loss = 17.05797415\n",
      "Iteration 7, loss = 14.51143741\n",
      "Iteration 8, loss = 13.10089109\n",
      "Iteration 9, loss = 12.20086162\n",
      "Iteration 10, loss = 11.62597727\n",
      "Iteration 11, loss = 11.11626810\n",
      "Iteration 12, loss = 10.81345696\n",
      "Iteration 13, loss = 10.48358195\n",
      "Iteration 14, loss = 10.41417149\n",
      "Iteration 15, loss = 10.32133774\n",
      "Iteration 16, loss = 10.14248415\n",
      "Iteration 17, loss = 10.08462679\n",
      "Iteration 18, loss = 10.01081337\n",
      "Iteration 19, loss = 9.89123982\n",
      "Iteration 20, loss = 9.86261946\n",
      "Iteration 21, loss = 9.79087557\n",
      "Iteration 22, loss = 9.77770678\n",
      "Iteration 23, loss = 9.66597303\n",
      "Iteration 24, loss = 9.69843039\n",
      "Iteration 25, loss = 9.65111497\n",
      "Iteration 26, loss = 9.61274771\n",
      "Iteration 27, loss = 9.62863564\n",
      "Iteration 28, loss = 9.60139047\n",
      "Iteration 29, loss = 9.61045305\n",
      "Iteration 30, loss = 9.57725852\n",
      "Iteration 31, loss = 9.50943023\n",
      "Iteration 32, loss = 9.56399323\n",
      "Iteration 33, loss = 9.50703104\n",
      "Iteration 34, loss = 9.43168785\n",
      "Iteration 35, loss = 9.43008995\n",
      "Iteration 36, loss = 9.49681876\n",
      "Iteration 37, loss = 9.43968060\n",
      "Iteration 38, loss = 9.46481699\n",
      "Iteration 39, loss = 9.43207241\n",
      "Iteration 40, loss = 9.34398982\n",
      "Iteration 41, loss = 9.31028352\n",
      "Iteration 42, loss = 9.27224954\n",
      "Iteration 43, loss = 9.26205469\n",
      "Iteration 44, loss = 9.23158024\n",
      "Iteration 45, loss = 9.28037902\n",
      "Iteration 46, loss = 9.21584620\n",
      "Iteration 47, loss = 9.24272940\n",
      "Iteration 48, loss = 9.30687695\n",
      "Iteration 49, loss = 9.18867506\n",
      "Iteration 50, loss = 9.22896546\n",
      "Iteration 51, loss = 9.19263807\n",
      "Iteration 52, loss = 9.18276677\n",
      "Iteration 53, loss = 9.12208257\n",
      "Iteration 54, loss = 9.10366236\n",
      "Iteration 55, loss = 9.10059331\n",
      "Iteration 56, loss = 9.09542622\n",
      "Iteration 57, loss = 9.06255523\n",
      "Iteration 58, loss = 9.14436043\n",
      "Iteration 59, loss = 9.15999172\n",
      "Iteration 60, loss = 9.11250445\n",
      "Iteration 61, loss = 9.07600735\n",
      "Iteration 62, loss = 9.06418517\n",
      "Iteration 63, loss = 9.06378773\n",
      "Iteration 64, loss = 9.01488104\n",
      "Iteration 65, loss = 9.05145605\n",
      "Iteration 66, loss = 9.04807720\n",
      "Iteration 67, loss = 9.03279312\n",
      "Iteration 68, loss = 8.98344818\n",
      "Iteration 69, loss = 8.98419995\n",
      "Iteration 70, loss = 9.02430396\n",
      "Iteration 71, loss = 9.01325916\n",
      "Iteration 72, loss = 9.08938423\n",
      "Iteration 73, loss = 8.95684132\n",
      "Iteration 74, loss = 9.06009035\n",
      "Iteration 75, loss = 9.01406244\n",
      "Iteration 76, loss = 8.99572559\n",
      "Iteration 77, loss = 8.98377647\n",
      "Iteration 78, loss = 8.98824706\n",
      "Iteration 79, loss = 9.00890980\n",
      "Iteration 80, loss = 9.01289688\n",
      "Iteration 81, loss = 8.93560622\n",
      "Iteration 82, loss = 8.95424302\n",
      "Iteration 83, loss = 8.97617272\n",
      "Iteration 84, loss = 8.95560530\n",
      "Iteration 85, loss = 8.88571627\n",
      "Iteration 86, loss = 8.94032131\n",
      "Iteration 87, loss = 8.90606773\n",
      "Iteration 88, loss = 8.95596529\n",
      "Iteration 89, loss = 8.95800486\n",
      "Iteration 90, loss = 8.94850624\n",
      "Iteration 91, loss = 8.85618631\n",
      "Iteration 92, loss = 8.93386888\n",
      "Iteration 93, loss = 8.86914763\n",
      "Iteration 94, loss = 8.88934272\n",
      "Iteration 95, loss = 8.85674606\n",
      "Iteration 96, loss = 8.89520390\n",
      "Iteration 97, loss = 8.84410632\n",
      "Iteration 98, loss = 8.89640534\n",
      "Iteration 99, loss = 8.88677752\n",
      "Iteration 100, loss = 8.89101699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 13338.15487702\n",
      "Iteration 2, loss = 876.37121940\n",
      "Iteration 3, loss = 117.41044644\n",
      "Iteration 4, loss = 36.21746859\n",
      "Iteration 5, loss = 21.85254631\n",
      "Iteration 6, loss = 17.20132677\n",
      "Iteration 7, loss = 14.74812032\n",
      "Iteration 8, loss = 13.45278324\n",
      "Iteration 9, loss = 12.53470977\n",
      "Iteration 10, loss = 11.91924185\n",
      "Iteration 11, loss = 11.45324250\n",
      "Iteration 12, loss = 11.08859246\n",
      "Iteration 13, loss = 10.76324282\n",
      "Iteration 14, loss = 10.59691827\n",
      "Iteration 15, loss = 10.38689421\n",
      "Iteration 16, loss = 10.26907381\n",
      "Iteration 17, loss = 10.12072954\n",
      "Iteration 18, loss = 10.02204096\n",
      "Iteration 19, loss = 9.95121919\n",
      "Iteration 20, loss = 9.88710679\n",
      "Iteration 21, loss = 9.84659405\n",
      "Iteration 22, loss = 9.71419653\n",
      "Iteration 23, loss = 9.67070625\n",
      "Iteration 24, loss = 9.57361618\n",
      "Iteration 25, loss = 9.52628835\n",
      "Iteration 26, loss = 9.51959579\n",
      "Iteration 27, loss = 9.43588351\n",
      "Iteration 28, loss = 9.34471916\n",
      "Iteration 29, loss = 9.28215442\n",
      "Iteration 30, loss = 9.21333300\n",
      "Iteration 31, loss = 9.28790878\n",
      "Iteration 32, loss = 9.21470029\n",
      "Iteration 33, loss = 9.21838912\n",
      "Iteration 34, loss = 9.19912056\n",
      "Iteration 35, loss = 9.15712100\n",
      "Iteration 36, loss = 9.11686198\n",
      "Iteration 37, loss = 9.12837492\n",
      "Iteration 38, loss = 9.09826406\n",
      "Iteration 39, loss = 9.08465434\n",
      "Iteration 40, loss = 9.00537943\n",
      "Iteration 41, loss = 9.01789234\n",
      "Iteration 42, loss = 8.99220492\n",
      "Iteration 43, loss = 9.01385234\n",
      "Iteration 44, loss = 8.94422320\n",
      "Iteration 45, loss = 8.95527778\n",
      "Iteration 46, loss = 8.97670943\n",
      "Iteration 47, loss = 8.88350492\n",
      "Iteration 48, loss = 8.91670541\n",
      "Iteration 49, loss = 8.85833215\n",
      "Iteration 50, loss = 8.90758236\n",
      "Iteration 51, loss = 8.86419185\n",
      "Iteration 52, loss = 8.79709010\n",
      "Iteration 53, loss = 8.78129380\n",
      "Iteration 54, loss = 8.84199693\n",
      "Iteration 55, loss = 8.80568718\n",
      "Iteration 56, loss = 8.78541117\n",
      "Iteration 57, loss = 8.80266629\n",
      "Iteration 58, loss = 8.69963774\n",
      "Iteration 59, loss = 8.78224521\n",
      "Iteration 60, loss = 8.79695079\n",
      "Iteration 61, loss = 8.74799770\n",
      "Iteration 62, loss = 8.74650506\n",
      "Iteration 63, loss = 8.71603400\n",
      "Iteration 64, loss = 8.69959052\n",
      "Iteration 65, loss = 8.71383255\n",
      "Iteration 66, loss = 8.71048794\n",
      "Iteration 67, loss = 8.79347167\n",
      "Iteration 68, loss = 8.68256562\n",
      "Iteration 69, loss = 8.71379043\n",
      "Iteration 70, loss = 8.71676962\n",
      "Iteration 71, loss = 8.75717156\n",
      "Iteration 72, loss = 8.66638164\n",
      "Iteration 73, loss = 8.65590395\n",
      "Iteration 74, loss = 8.63914965\n",
      "Iteration 75, loss = 8.59341970\n",
      "Iteration 76, loss = 8.63350755\n",
      "Iteration 77, loss = 8.61349641\n",
      "Iteration 78, loss = 8.64450321\n",
      "Iteration 79, loss = 8.63319064\n",
      "Iteration 80, loss = 8.63015547\n",
      "Iteration 81, loss = 8.60682551\n",
      "Iteration 82, loss = 8.65907573\n",
      "Iteration 83, loss = 8.59947103\n",
      "Iteration 84, loss = 8.59685049\n",
      "Iteration 85, loss = 8.60986789\n",
      "Iteration 86, loss = 8.59370938\n",
      "Iteration 87, loss = 8.63107826\n",
      "Iteration 88, loss = 8.62031653\n",
      "Iteration 89, loss = 8.60605903\n",
      "Iteration 90, loss = 8.57961430\n",
      "Iteration 91, loss = 8.55252326\n",
      "Iteration 92, loss = 8.61499594\n",
      "Iteration 93, loss = 8.55044550\n",
      "Iteration 94, loss = 8.54006179\n",
      "Iteration 95, loss = 8.54765400\n",
      "Iteration 96, loss = 8.58965892\n",
      "Iteration 97, loss = 8.54202335\n",
      "Iteration 98, loss = 8.53525439\n",
      "Iteration 99, loss = 8.52502800\n",
      "Iteration 100, loss = 8.54499673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "results = find_best_feature_reduction(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('area',): 5.099858216678731,\n",
       " ('tmax',): 4.897088939036051,\n",
       " ('rms',): 4.875721949870735,\n",
       " ('area', 'tmax'): 4.932731016850282,\n",
       " ('area', 'rms'): 4.813012135913863,\n",
       " ('rms', 'tmax'): 4.810926736529878,\n",
       " ('area', 'tmax', 'rms'): 4.681118470934068}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import helpers.processing_helpers as ph\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.neural_network import  MLPRegressor\n",
    "\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv(\"./dataset/development.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_indexes = [0,7,12,15,16,17]\n",
    "acc_idxs = [1,2,3,4,5,6,8,9,10,11,13,14]\n",
    "features = [\"pmax\", \"negpmax\", 'area', 'tmax', 'rms']\n",
    "\n",
    "sensors_removed = df_dev.drop(columns=ph.get_column_names(features, noise_indexes))\n",
    "df = sensors_removed.drop(columns=ph.get_column_names(['tmax', 'rms', 'area'], acc_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = make_scorer(ph.mean_euclid_dist, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be the constant parameters\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', MLPRegressor(random_state=42, max_iter=200, n_iter_no_change=50, learning_rate_init=0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df[['x', 'y']].copy()\n",
    "\n",
    "X_train = df.drop(columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'clf__hidden_layer_sizes' : [(50,),\n",
    "                                            (25, 25),\n",
    "                                            (35, 15),\n",
    "                                            (20, 10, 20),\n",
    "                                            (25, 15, 10),\n",
    "                                            (20, 15, 10, 5),\n",
    "                                            (15, 10, 10, 15)],\n",
    "            'activation' : ['relu', \n",
    "                              'logistic', \n",
    "                              'tanh', \n",
    "                              'identity'],\n",
    "            'learning_rate_init': [0.01, 0.001],\n",
    "            'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "            'solver': ['adam', 'sgd', 'lbfgs']\n",
    "\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arist\\OneDrive\\Skrivebord\\DSL labs\\DSL_project2\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "Iteration 1, loss = 12476.91642696\n",
      "Iteration 2, loss = 1701.87472122\n",
      "Iteration 3, loss = 646.01684514\n",
      "Iteration 4, loss = 324.03285687\n",
      "Iteration 5, loss = 175.15264284\n",
      "Iteration 6, loss = 97.32800108\n",
      "Iteration 7, loss = 64.30712714\n",
      "Iteration 8, loss = 77.17069816\n",
      "Iteration 9, loss = 45.62285844\n",
      "Iteration 10, loss = 65.01094176\n",
      "Iteration 11, loss = 124.52389398\n",
      "Iteration 12, loss = 32.50848970\n",
      "Iteration 13, loss = 52.90667962\n",
      "Iteration 14, loss = 83.55195840\n",
      "Iteration 15, loss = 43.76390283\n",
      "Iteration 16, loss = 83.00284752\n",
      "Iteration 17, loss = 54.99950965\n",
      "Iteration 18, loss = 45.13281692\n",
      "Iteration 19, loss = 64.99761304\n",
      "Iteration 20, loss = 59.78991050\n",
      "Iteration 21, loss = 36.80326381\n",
      "Iteration 22, loss = 55.08150041\n",
      "Iteration 23, loss = 66.04854237\n",
      "Iteration 24, loss = 35.53814980\n",
      "Iteration 25, loss = 54.66363994\n",
      "Iteration 26, loss = 44.62134056\n",
      "Iteration 27, loss = 39.98376974\n",
      "Iteration 28, loss = 57.75110244\n",
      "Iteration 29, loss = 52.85520067\n",
      "Iteration 30, loss = 30.41510412\n",
      "Iteration 31, loss = 37.66288701\n",
      "Iteration 32, loss = 34.76165535\n",
      "Iteration 33, loss = 38.93624880\n",
      "Iteration 34, loss = 42.26540206\n",
      "Iteration 35, loss = 37.64684545\n",
      "Iteration 36, loss = 39.26524095\n",
      "Iteration 37, loss = 35.03734685\n",
      "Iteration 38, loss = 40.09631898\n",
      "Iteration 39, loss = 35.10902388\n",
      "Iteration 40, loss = 36.19805125\n",
      "Iteration 41, loss = 42.28896126\n",
      "Iteration 42, loss = 27.17514163\n",
      "Iteration 43, loss = 36.89881521\n",
      "Iteration 44, loss = 34.38651393\n",
      "Iteration 45, loss = 31.58573532\n",
      "Iteration 46, loss = 34.41457912\n",
      "Iteration 47, loss = 34.24141809\n",
      "Iteration 48, loss = 25.62662638\n",
      "Iteration 49, loss = 24.29647366\n",
      "Iteration 50, loss = 49.29202563\n",
      "Iteration 51, loss = 23.01946924\n",
      "Iteration 52, loss = 29.36310273\n",
      "Iteration 53, loss = 28.80367285\n",
      "Iteration 54, loss = 26.62127278\n",
      "Iteration 55, loss = 35.00906912\n",
      "Iteration 56, loss = 27.01542102\n",
      "Iteration 57, loss = 27.54243420\n",
      "Iteration 58, loss = 31.45537118\n",
      "Iteration 59, loss = 20.21405438\n",
      "Iteration 60, loss = 34.10001857\n",
      "Iteration 61, loss = 31.78627403\n",
      "Iteration 62, loss = 27.10274637\n",
      "Iteration 63, loss = 19.88991434\n",
      "Iteration 64, loss = 31.49027250\n",
      "Iteration 65, loss = 27.17265088\n",
      "Iteration 66, loss = 20.89775737\n",
      "Iteration 67, loss = 29.05300376\n",
      "Iteration 68, loss = 22.19987408\n",
      "Iteration 69, loss = 19.74039925\n",
      "Iteration 70, loss = 29.68741801\n",
      "Iteration 71, loss = 25.58503230\n",
      "Iteration 72, loss = 24.31195772\n",
      "Iteration 73, loss = 18.40629677\n",
      "Iteration 74, loss = 19.27925457\n",
      "Iteration 75, loss = 25.38131480\n",
      "Iteration 76, loss = 32.07210862\n",
      "Iteration 77, loss = 18.08815896\n",
      "Iteration 78, loss = 23.55553948\n",
      "Iteration 79, loss = 22.13905674\n",
      "Iteration 80, loss = 24.11915056\n",
      "Iteration 81, loss = 23.05791312\n",
      "Iteration 82, loss = 25.28550029\n",
      "Iteration 83, loss = 20.41831500\n",
      "Iteration 84, loss = 21.13866760\n",
      "Iteration 85, loss = 23.37086420\n",
      "Iteration 86, loss = 21.59731342\n",
      "Iteration 87, loss = 18.19986474\n",
      "Iteration 88, loss = 23.53876019\n",
      "Iteration 89, loss = 18.29614401\n",
      "Iteration 90, loss = 20.01178571\n",
      "Iteration 91, loss = 23.83553219\n",
      "Iteration 92, loss = 22.99965510\n",
      "Iteration 93, loss = 21.54086183\n",
      "Iteration 94, loss = 19.21256534\n",
      "Iteration 95, loss = 21.45677424\n",
      "Iteration 96, loss = 22.97917443\n",
      "Iteration 97, loss = 19.94787078\n",
      "Iteration 98, loss = 23.91058743\n",
      "Iteration 99, loss = 22.15355576\n",
      "Iteration 100, loss = 18.36235234\n",
      "[CV] END ......................clf__hidden_layer_sizes=(50,); total time=  43.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arist\\OneDrive\\Skrivebord\\DSL labs\\DSL_project2\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 8027.86437007\n",
      "Iteration 2, loss = 1467.45210186\n",
      "Iteration 3, loss = 512.82774784\n",
      "Iteration 4, loss = 229.00750994\n",
      "Iteration 5, loss = 121.19102992\n",
      "Iteration 6, loss = 62.27620708\n",
      "Iteration 7, loss = 64.08477093\n",
      "Iteration 8, loss = 55.79962132\n",
      "Iteration 9, loss = 38.99814447\n",
      "Iteration 10, loss = 48.35815299\n",
      "Iteration 11, loss = 78.15915010\n",
      "Iteration 12, loss = 49.36284763\n",
      "Iteration 13, loss = 70.38944065\n",
      "Iteration 14, loss = 40.03010970\n",
      "Iteration 15, loss = 38.99511652\n",
      "Iteration 16, loss = 54.57515521\n",
      "Iteration 17, loss = 38.03828740\n",
      "Iteration 18, loss = 47.71726854\n",
      "Iteration 19, loss = 44.77633976\n",
      "Iteration 20, loss = 40.58537966\n",
      "Iteration 21, loss = 46.96459667\n",
      "Iteration 22, loss = 39.79053485\n",
      "Iteration 23, loss = 32.09421116\n",
      "Iteration 24, loss = 44.14699807\n",
      "Iteration 25, loss = 39.07180948\n",
      "Iteration 26, loss = 34.15333840\n",
      "Iteration 27, loss = 33.03196401\n",
      "Iteration 28, loss = 43.00503466\n",
      "Iteration 29, loss = 24.39621139\n",
      "Iteration 30, loss = 33.35304160\n",
      "Iteration 31, loss = 27.82655146\n",
      "Iteration 32, loss = 35.83926047\n",
      "Iteration 33, loss = 35.44576077\n",
      "Iteration 34, loss = 26.58911928\n",
      "Iteration 35, loss = 25.21516499\n",
      "Iteration 36, loss = 30.22845688\n",
      "Iteration 37, loss = 24.48574956\n",
      "Iteration 38, loss = 24.05598344\n",
      "Iteration 39, loss = 29.31890194\n",
      "Iteration 40, loss = 25.00930410\n",
      "Iteration 41, loss = 19.85085712\n",
      "Iteration 42, loss = 32.86714832\n",
      "Iteration 43, loss = 29.71379040\n",
      "Iteration 44, loss = 24.08634370\n",
      "Iteration 45, loss = 25.38824676\n",
      "Iteration 46, loss = 23.27348776\n",
      "Iteration 47, loss = 24.42642710\n",
      "Iteration 48, loss = 22.34724493\n",
      "Iteration 49, loss = 19.89575700\n",
      "Iteration 50, loss = 24.60058871\n",
      "Iteration 51, loss = 22.48589861\n",
      "Iteration 52, loss = 19.55679152\n",
      "Iteration 53, loss = 19.02919152\n",
      "Iteration 54, loss = 26.46507855\n",
      "Iteration 55, loss = 23.72371972\n",
      "Iteration 56, loss = 21.91927317\n",
      "Iteration 57, loss = 19.81258760\n",
      "Iteration 58, loss = 16.88659948\n",
      "Iteration 59, loss = 24.80469618\n",
      "Iteration 60, loss = 19.72422327\n",
      "Iteration 61, loss = 20.09914915\n",
      "Iteration 62, loss = 18.30743082\n",
      "Iteration 63, loss = 21.42052981\n",
      "Iteration 64, loss = 19.37523281\n",
      "Iteration 65, loss = 17.94780003\n",
      "Iteration 66, loss = 21.27154489\n",
      "Iteration 67, loss = 22.72341741\n",
      "Iteration 68, loss = 19.08298569\n",
      "Iteration 69, loss = 18.41614810\n",
      "Iteration 70, loss = 16.76119416\n",
      "Iteration 71, loss = 20.31051566\n",
      "Iteration 72, loss = 20.44688464\n",
      "Iteration 73, loss = 18.64620028\n",
      "Iteration 74, loss = 17.58580194\n",
      "Iteration 75, loss = 19.37578910\n",
      "Iteration 76, loss = 19.20701933\n",
      "Iteration 77, loss = 16.16522715\n",
      "Iteration 78, loss = 17.72504108\n",
      "Iteration 79, loss = 18.00073285\n",
      "Iteration 80, loss = 17.37251378\n",
      "Iteration 81, loss = 18.98160252\n",
      "Iteration 82, loss = 19.18744183\n",
      "Iteration 83, loss = 16.75489498\n",
      "Iteration 84, loss = 16.06569393\n",
      "Iteration 85, loss = 18.26542827\n",
      "Iteration 86, loss = 19.51492318\n",
      "Iteration 87, loss = 18.28695001\n",
      "Iteration 88, loss = 17.56381056\n",
      "Iteration 89, loss = 17.62145401\n",
      "Iteration 90, loss = 18.02941181\n",
      "Iteration 91, loss = 17.30595318\n",
      "Iteration 92, loss = 19.91198822\n",
      "Iteration 93, loss = 17.06031049\n",
      "Iteration 94, loss = 18.16293803\n",
      "Iteration 95, loss = 14.79493602\n",
      "Iteration 96, loss = 17.62382863\n",
      "Iteration 97, loss = 15.99595026\n",
      "Iteration 98, loss = 15.29536534\n",
      "Iteration 99, loss = 20.18104774\n",
      "Iteration 100, loss = 18.07795607\n",
      "[CV] END ......................clf__hidden_layer_sizes=(50,); total time=  43.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arist\\OneDrive\\Skrivebord\\DSL labs\\DSL_project2\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 8746.54849544\n",
      "Iteration 2, loss = 840.78609435\n",
      "Iteration 3, loss = 283.90520463\n",
      "Iteration 4, loss = 131.46633513\n",
      "Iteration 5, loss = 71.60495206\n",
      "Iteration 6, loss = 67.42940745\n",
      "Iteration 7, loss = 142.35511363\n",
      "Iteration 8, loss = 141.67505979\n",
      "Iteration 9, loss = 74.18470713\n",
      "Iteration 10, loss = 213.82524859\n",
      "Iteration 11, loss = 38.18498751\n",
      "Iteration 12, loss = 204.53179576\n",
      "Iteration 13, loss = 71.26395213\n",
      "Iteration 14, loss = 61.40698713\n",
      "Iteration 15, loss = 40.70893790\n",
      "Iteration 16, loss = 42.99095910\n",
      "Iteration 17, loss = 37.10942710\n",
      "Iteration 18, loss = 74.99682619\n",
      "Iteration 19, loss = 31.32852548\n",
      "Iteration 20, loss = 32.30071715\n",
      "Iteration 21, loss = 30.49258744\n",
      "Iteration 22, loss = 27.13352214\n",
      "Iteration 23, loss = 24.64717527\n",
      "Iteration 24, loss = 22.66450427\n",
      "Iteration 25, loss = 26.63492187\n",
      "Iteration 26, loss = 23.00339443\n",
      "Iteration 27, loss = 26.33183671\n",
      "Iteration 28, loss = 34.67536976\n",
      "Iteration 29, loss = 23.28009431\n",
      "Iteration 30, loss = 22.09987646\n",
      "Iteration 31, loss = 23.43441200\n",
      "Iteration 32, loss = 24.44102661\n",
      "Iteration 33, loss = 18.62943392\n",
      "Iteration 34, loss = 22.51155985\n",
      "Iteration 35, loss = 21.26658349\n",
      "Iteration 36, loss = 31.35177345\n",
      "Iteration 37, loss = 27.99626456\n",
      "Iteration 38, loss = 28.89203198\n",
      "Iteration 39, loss = 22.48808354\n",
      "Iteration 40, loss = 17.55456822\n",
      "Iteration 41, loss = 20.31403609\n",
      "Iteration 42, loss = 20.59397665\n",
      "Iteration 43, loss = 26.61566008\n",
      "Iteration 44, loss = 16.67511240\n",
      "Iteration 45, loss = 19.85468020\n",
      "Iteration 46, loss = 21.69243980\n",
      "Iteration 47, loss = 20.63664050\n",
      "Iteration 48, loss = 19.99276993\n",
      "Iteration 49, loss = 22.98945513\n",
      "Iteration 50, loss = 20.16304936\n",
      "Iteration 51, loss = 17.89867053\n",
      "Iteration 52, loss = 25.02393262\n",
      "Iteration 53, loss = 18.60713543\n",
      "Iteration 54, loss = 15.43512415\n",
      "Iteration 55, loss = 21.08988386\n",
      "Iteration 56, loss = 20.78828669\n",
      "Iteration 57, loss = 19.16569226\n",
      "Iteration 58, loss = 16.31107082\n",
      "Iteration 59, loss = 16.12030487\n",
      "Iteration 60, loss = 17.77238488\n",
      "Iteration 61, loss = 33.62432650\n",
      "Iteration 62, loss = 24.74111057\n",
      "Iteration 63, loss = 23.99313005\n",
      "Iteration 64, loss = 17.72825198\n",
      "Iteration 65, loss = 16.06422086\n",
      "Iteration 66, loss = 15.43684936\n",
      "Iteration 67, loss = 21.17422757\n",
      "Iteration 68, loss = 18.19968370\n",
      "Iteration 69, loss = 17.12644130\n",
      "Iteration 70, loss = 16.50078753\n",
      "Iteration 71, loss = 28.78213491\n",
      "Iteration 72, loss = 15.41425976\n",
      "Iteration 73, loss = 19.11608214\n",
      "Iteration 74, loss = 19.55586511\n",
      "Iteration 75, loss = 16.91113189\n",
      "Iteration 76, loss = 15.26716994\n",
      "Iteration 77, loss = 18.05105341\n",
      "Iteration 78, loss = 18.80352417\n",
      "Iteration 79, loss = 17.36246488\n",
      "Iteration 80, loss = 23.28575284\n",
      "Iteration 81, loss = 15.71113916\n",
      "Iteration 82, loss = 15.39192007\n",
      "Iteration 83, loss = 24.68886572\n",
      "Iteration 84, loss = 17.36886873\n",
      "Iteration 85, loss = 16.84054001\n",
      "Iteration 86, loss = 18.25799461\n",
      "Iteration 87, loss = 14.41443376\n",
      "Iteration 88, loss = 19.46346120\n",
      "Iteration 89, loss = 14.96507832\n",
      "Iteration 90, loss = 15.45093184\n",
      "Iteration 91, loss = 27.44226091\n",
      "Iteration 92, loss = 15.04151097\n",
      "Iteration 93, loss = 16.13821784\n",
      "Iteration 94, loss = 15.95681596\n",
      "Iteration 95, loss = 16.82806785\n",
      "Iteration 96, loss = 15.22053742\n",
      "Iteration 97, loss = 15.25936896\n",
      "Iteration 98, loss = 21.80279855\n",
      "Iteration 99, loss = 19.05519719\n",
      "Iteration 100, loss = 21.93824864\n",
      "[CV] END ...................clf__hidden_layer_sizes=(25, 25); total time=  50.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arist\\OneDrive\\Skrivebord\\DSL labs\\DSL_project2\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4540.08198068\n",
      "Iteration 2, loss = 521.82455626\n",
      "Iteration 3, loss = 145.68090906\n",
      "Iteration 4, loss = 60.39351928\n",
      "Iteration 5, loss = 53.44974077\n",
      "Iteration 6, loss = 44.66813084\n",
      "Iteration 7, loss = 35.13936042\n",
      "Iteration 8, loss = 35.74941212\n",
      "Iteration 9, loss = 41.30107488\n",
      "Iteration 10, loss = 31.57642061\n",
      "Iteration 11, loss = 32.16087283\n",
      "Iteration 12, loss = 27.78029185\n",
      "Iteration 13, loss = 36.40318444\n",
      "Iteration 14, loss = 38.34821086\n",
      "Iteration 15, loss = 25.10119376\n",
      "Iteration 16, loss = 26.77696209\n",
      "Iteration 17, loss = 35.43774389\n",
      "Iteration 18, loss = 24.81109207\n",
      "Iteration 19, loss = 21.67071266\n",
      "Iteration 20, loss = 19.95866048\n",
      "Iteration 21, loss = 22.99154649\n",
      "Iteration 22, loss = 19.58774525\n",
      "Iteration 23, loss = 31.66121475\n",
      "Iteration 24, loss = 19.50897357\n",
      "Iteration 25, loss = 18.76692971\n",
      "Iteration 26, loss = 24.71978261\n",
      "Iteration 27, loss = 24.42974398\n",
      "Iteration 28, loss = 21.28307044\n",
      "Iteration 29, loss = 18.91396258\n",
      "Iteration 30, loss = 20.46383125\n",
      "Iteration 31, loss = 22.16389928\n",
      "Iteration 32, loss = 24.85992074\n",
      "Iteration 33, loss = 18.38965800\n",
      "Iteration 34, loss = 17.56289687\n",
      "Iteration 35, loss = 17.23857324\n",
      "Iteration 36, loss = 14.70841592\n",
      "Iteration 37, loss = 22.51792140\n",
      "Iteration 38, loss = 34.39207374\n",
      "Iteration 39, loss = 15.68815874\n",
      "Iteration 40, loss = 17.66920672\n",
      "Iteration 41, loss = 18.46080031\n",
      "Iteration 42, loss = 17.23297806\n",
      "Iteration 43, loss = 17.05805967\n",
      "Iteration 44, loss = 14.78326130\n",
      "Iteration 45, loss = 19.43239923\n",
      "Iteration 46, loss = 17.09831242\n",
      "Iteration 47, loss = 14.36897656\n",
      "Iteration 48, loss = 17.07302363\n",
      "Iteration 49, loss = 19.90282089\n",
      "Iteration 50, loss = 24.45694915\n",
      "Iteration 51, loss = 20.83481700\n",
      "Iteration 52, loss = 18.20596124\n",
      "Iteration 53, loss = 14.74433140\n",
      "Iteration 54, loss = 15.69452031\n",
      "Iteration 55, loss = 15.48062820\n",
      "Iteration 56, loss = 13.29597695\n",
      "Iteration 57, loss = 13.94519126\n",
      "Iteration 58, loss = 25.53032008\n",
      "Iteration 59, loss = 24.94032757\n",
      "Iteration 60, loss = 16.23311075\n",
      "Iteration 61, loss = 14.66689892\n",
      "Iteration 62, loss = 19.36737478\n",
      "Iteration 63, loss = 26.42585705\n",
      "Iteration 64, loss = 15.88088612\n",
      "Iteration 65, loss = 15.33797513\n",
      "Iteration 66, loss = 14.55833646\n",
      "Iteration 67, loss = 16.40356070\n",
      "Iteration 68, loss = 14.93994332\n",
      "Iteration 69, loss = 14.45109197\n",
      "Iteration 70, loss = 13.98761414\n",
      "Iteration 71, loss = 22.34950157\n",
      "Iteration 72, loss = 14.35149064\n",
      "Iteration 73, loss = 12.52648770\n",
      "Iteration 74, loss = 15.00135540\n",
      "Iteration 75, loss = 28.90756173\n",
      "Iteration 76, loss = 13.80355207\n",
      "Iteration 77, loss = 17.59095918\n",
      "Iteration 78, loss = 16.91630609\n",
      "Iteration 79, loss = 13.56174239\n",
      "Iteration 80, loss = 17.71450685\n",
      "Iteration 81, loss = 36.26164013\n",
      "Iteration 82, loss = 15.25307130\n",
      "Iteration 83, loss = 13.73654257\n",
      "Iteration 84, loss = 14.18996798\n",
      "Iteration 85, loss = 17.44235852\n",
      "Iteration 86, loss = 24.06908919\n",
      "Iteration 87, loss = 15.09553458\n",
      "Iteration 88, loss = 13.87624679\n",
      "Iteration 89, loss = 15.16494490\n",
      "Iteration 90, loss = 16.95127558\n",
      "Iteration 91, loss = 14.03220255\n",
      "Iteration 92, loss = 17.77223362\n",
      "Iteration 93, loss = 17.77843883\n",
      "Iteration 94, loss = 13.50069092\n",
      "Iteration 95, loss = 16.97264715\n",
      "Iteration 96, loss = 18.72407748\n",
      "Iteration 97, loss = 15.35309146\n",
      "Iteration 98, loss = 15.05916922\n",
      "Iteration 99, loss = 13.07758735\n",
      "Iteration 100, loss = 13.26020993\n",
      "[CV] END ...................clf__hidden_layer_sizes=(25, 25); total time=  52.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arist\\OneDrive\\Skrivebord\\DSL labs\\DSL_project2\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 7426.46400611\n",
      "Iteration 2, loss = 2220.60306852\n",
      "Iteration 3, loss = 541.93353666\n",
      "Iteration 4, loss = 208.85396506\n",
      "Iteration 5, loss = 139.03809294\n",
      "Iteration 6, loss = 76.00543436\n",
      "Iteration 7, loss = 53.16537345\n",
      "Iteration 8, loss = 48.70275953\n",
      "Iteration 9, loss = 37.84653836\n",
      "Iteration 10, loss = 38.41030891\n",
      "Iteration 11, loss = 33.88332825\n",
      "Iteration 12, loss = 28.65500957\n",
      "Iteration 13, loss = 40.11522281\n",
      "Iteration 14, loss = 36.71473345\n",
      "Iteration 15, loss = 30.82140019\n",
      "Iteration 16, loss = 35.03683666\n",
      "Iteration 17, loss = 42.92439148\n",
      "Iteration 18, loss = 30.43497949\n",
      "Iteration 19, loss = 27.47120770\n",
      "Iteration 20, loss = 29.85172449\n",
      "Iteration 21, loss = 30.82634448\n",
      "Iteration 22, loss = 53.16137172\n",
      "Iteration 23, loss = 29.19361659\n",
      "Iteration 24, loss = 26.23701577\n",
      "Iteration 25, loss = 25.52753857\n",
      "Iteration 26, loss = 32.40008313\n",
      "Iteration 27, loss = 27.12991220\n",
      "Iteration 28, loss = 24.08126081\n",
      "Iteration 29, loss = 24.84623497\n",
      "Iteration 30, loss = 25.56916035\n",
      "Iteration 31, loss = 23.89733668\n",
      "Iteration 32, loss = 21.92413198\n",
      "Iteration 33, loss = 29.98661545\n",
      "Iteration 34, loss = 39.52598187\n",
      "Iteration 35, loss = 21.74447090\n",
      "Iteration 36, loss = 22.10659467\n",
      "Iteration 37, loss = 23.01881660\n",
      "Iteration 38, loss = 30.44986400\n",
      "Iteration 39, loss = 21.40533239\n",
      "Iteration 40, loss = 17.91047188\n",
      "Iteration 41, loss = 27.88169566\n",
      "Iteration 42, loss = 18.11561450\n",
      "Iteration 43, loss = 25.08043381\n",
      "Iteration 44, loss = 24.52362817\n",
      "Iteration 45, loss = 20.35085315\n",
      "Iteration 46, loss = 23.47040189\n",
      "Iteration 47, loss = 23.57503170\n",
      "Iteration 48, loss = 19.19694989\n",
      "Iteration 49, loss = 18.69300563\n",
      "Iteration 50, loss = 28.66208028\n",
      "Iteration 51, loss = 31.57087088\n",
      "Iteration 52, loss = 17.73920105\n",
      "Iteration 53, loss = 17.06668458\n",
      "Iteration 54, loss = 27.57340323\n",
      "Iteration 55, loss = 20.44883528\n",
      "Iteration 56, loss = 24.92061487\n",
      "Iteration 57, loss = 20.59859718\n",
      "Iteration 58, loss = 18.41550099\n",
      "Iteration 59, loss = 26.04882031\n",
      "Iteration 60, loss = 17.74119520\n",
      "Iteration 61, loss = 15.33637565\n",
      "Iteration 62, loss = 29.50364077\n",
      "Iteration 63, loss = 20.77124451\n",
      "Iteration 64, loss = 16.90142574\n",
      "Iteration 65, loss = 15.63111276\n",
      "Iteration 66, loss = 22.79823245\n",
      "Iteration 67, loss = 19.46275089\n",
      "Iteration 68, loss = 15.67313643\n",
      "Iteration 69, loss = 20.05073416\n",
      "Iteration 70, loss = 20.63840326\n",
      "Iteration 71, loss = 22.12233982\n",
      "Iteration 72, loss = 14.39100375\n",
      "Iteration 73, loss = 14.13571146\n",
      "Iteration 74, loss = 13.94549303\n",
      "Iteration 75, loss = 19.97478492\n",
      "Iteration 76, loss = 18.47825722\n",
      "Iteration 77, loss = 13.71448687\n",
      "Iteration 78, loss = 16.23021150\n",
      "Iteration 79, loss = 19.11885410\n",
      "Iteration 80, loss = 14.76852404\n",
      "Iteration 81, loss = 13.24064060\n",
      "Iteration 82, loss = 44.37362701\n",
      "Iteration 83, loss = 14.60762481\n",
      "Iteration 84, loss = 24.02177706\n",
      "Iteration 85, loss = 13.02914161\n",
      "Iteration 86, loss = 15.14289264\n",
      "Iteration 87, loss = 23.17617981\n",
      "Iteration 88, loss = 13.38125162\n",
      "Iteration 89, loss = 15.77226994\n",
      "Iteration 90, loss = 14.51231513\n",
      "Iteration 91, loss = 14.18624739\n",
      "Iteration 92, loss = 15.10521759\n",
      "Iteration 93, loss = 13.17397935\n",
      "Iteration 94, loss = 13.37543066\n",
      "Iteration 95, loss = 14.34818402\n",
      "Iteration 96, loss = 17.39122471\n",
      "Iteration 97, loss = 15.86982059\n",
      "Iteration 98, loss = 16.57905142\n",
      "Iteration 99, loss = 16.75917596\n",
      "Iteration 100, loss = 12.26010276\n",
      "[CV] END ...........clf__hidden_layer_sizes=(15, 10, 10, 15); total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arist\\OneDrive\\Skrivebord\\DSL labs\\DSL_project2\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4027.14480150\n",
      "Iteration 2, loss = 289.78982764\n",
      "Iteration 3, loss = 77.43321550\n",
      "Iteration 4, loss = 44.55176176\n",
      "Iteration 5, loss = 42.04972750\n",
      "Iteration 6, loss = 34.34948195\n",
      "Iteration 7, loss = 33.01159778\n",
      "Iteration 8, loss = 33.18061441\n",
      "Iteration 9, loss = 34.89048448\n",
      "Iteration 10, loss = 30.49709237\n",
      "Iteration 11, loss = 48.40548871\n",
      "Iteration 12, loss = 26.05190563\n",
      "Iteration 13, loss = 26.11229126\n",
      "Iteration 14, loss = 181.39050136\n",
      "Iteration 15, loss = 42.15313121\n",
      "Iteration 16, loss = 27.53808430\n",
      "Iteration 17, loss = 28.85322165\n",
      "Iteration 18, loss = 22.16913270\n",
      "Iteration 19, loss = 20.08923011\n",
      "Iteration 20, loss = 17.83796005\n",
      "Iteration 21, loss = 17.61153616\n",
      "Iteration 22, loss = 38.44514929\n",
      "Iteration 23, loss = 50.36096301\n",
      "Iteration 24, loss = 22.03884015\n",
      "Iteration 25, loss = 16.83749098\n",
      "Iteration 26, loss = 16.14717546\n",
      "Iteration 27, loss = 16.19348134\n",
      "Iteration 28, loss = 15.33871356\n",
      "Iteration 29, loss = 15.30206180\n",
      "Iteration 30, loss = 16.89929246\n",
      "Iteration 31, loss = 21.29800815\n",
      "Iteration 32, loss = 15.62402175\n",
      "Iteration 33, loss = 17.37523026\n",
      "Iteration 34, loss = 14.36522049\n",
      "Iteration 35, loss = 14.25360781\n",
      "Iteration 36, loss = 13.83812914\n",
      "Iteration 37, loss = 13.59115145\n",
      "Iteration 38, loss = 20.02588739\n",
      "Iteration 39, loss = 21.14493568\n",
      "Iteration 40, loss = 13.65778213\n",
      "Iteration 41, loss = 13.13842345\n",
      "Iteration 42, loss = 13.46758376\n",
      "Iteration 43, loss = 19.28868277\n",
      "Iteration 44, loss = 13.61763927\n",
      "Iteration 45, loss = 13.34093960\n",
      "Iteration 46, loss = 15.56758095\n",
      "Iteration 47, loss = 13.02809959\n",
      "Iteration 48, loss = 12.81233778\n",
      "Iteration 49, loss = 12.93668747\n",
      "Iteration 50, loss = 12.58374422\n",
      "Iteration 51, loss = 12.79637773\n",
      "Iteration 52, loss = 22.62722363\n",
      "Iteration 53, loss = 21.43540843\n",
      "Iteration 54, loss = 13.39797023\n",
      "Iteration 55, loss = 13.06953681\n",
      "Iteration 56, loss = 13.81233048\n",
      "Iteration 57, loss = 14.84038115\n",
      "Iteration 58, loss = 12.84653999\n",
      "Iteration 59, loss = 14.20428160\n",
      "Iteration 60, loss = 13.91293424\n",
      "Iteration 61, loss = 20.79187524\n",
      "Iteration 62, loss = 15.71818008\n",
      "Iteration 63, loss = 16.58440047\n",
      "Iteration 64, loss = 19.78372167\n",
      "Iteration 65, loss = 12.90303807\n",
      "Iteration 66, loss = 13.05745782\n",
      "Iteration 67, loss = 13.30585381\n",
      "Iteration 68, loss = 13.09880067\n",
      "Iteration 69, loss = 12.90606726\n",
      "Iteration 70, loss = 13.11431560\n",
      "Iteration 71, loss = 13.11901928\n",
      "Iteration 72, loss = 12.34499689\n",
      "Iteration 73, loss = 13.23817274\n",
      "Iteration 74, loss = 12.52556415\n",
      "Iteration 75, loss = 12.73199099\n",
      "Iteration 76, loss = 12.24416783\n",
      "Iteration 77, loss = 13.65370109\n",
      "Iteration 78, loss = 12.34049567\n",
      "Iteration 79, loss = 13.42182533\n",
      "Iteration 80, loss = 12.91508792\n",
      "Iteration 81, loss = 12.38322155\n",
      "Iteration 82, loss = 12.71046138\n",
      "Iteration 83, loss = 12.36647810\n",
      "Iteration 84, loss = 158.49341023\n",
      "Iteration 85, loss = 50.69550315\n",
      "Iteration 86, loss = 18.17898323\n",
      "Iteration 87, loss = 81.05715378\n",
      "Iteration 88, loss = 16.45657400\n",
      "Iteration 89, loss = 15.03218690\n",
      "Iteration 90, loss = 16.06487819\n",
      "Iteration 91, loss = 15.13672705\n",
      "Iteration 92, loss = 81.70129958\n",
      "Iteration 93, loss = 21.70072020\n",
      "Iteration 94, loss = 19.40157616\n",
      "Iteration 95, loss = 16.88713226\n",
      "Iteration 96, loss = 16.24694863\n",
      "Iteration 97, loss = 15.84499254\n",
      "Iteration 98, loss = 14.57045863\n",
      "Iteration 99, loss = 15.74653648\n",
      "Iteration 100, loss = 14.57387616\n",
      "[CV] END ...........clf__hidden_layer_sizes=(15, 10, 10, 15); total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arist\\OneDrive\\Skrivebord\\DSL labs\\DSL_project2\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 6088.23951202\n",
      "Iteration 2, loss = 320.24730860\n",
      "Iteration 3, loss = 111.51786205\n",
      "Iteration 4, loss = 87.96363576\n",
      "Iteration 5, loss = 54.78344094\n",
      "Iteration 6, loss = 41.60994654\n",
      "Iteration 7, loss = 45.05554019\n",
      "Iteration 8, loss = 39.40811087\n",
      "Iteration 9, loss = 44.39127653\n",
      "Iteration 10, loss = 35.89191625\n",
      "Iteration 11, loss = 50.27450081\n",
      "Iteration 12, loss = 33.45792945\n",
      "Iteration 13, loss = 45.26990214\n",
      "Iteration 14, loss = 29.12530637\n",
      "Iteration 15, loss = 62.84037896\n",
      "Iteration 16, loss = 32.00469521\n",
      "Iteration 17, loss = 32.45966901\n",
      "Iteration 18, loss = 26.88837752\n",
      "Iteration 19, loss = 40.26918716\n",
      "Iteration 20, loss = 29.67582756\n",
      "Iteration 21, loss = 29.72316586\n",
      "Iteration 22, loss = 35.65800701\n",
      "Iteration 23, loss = 31.73199655\n",
      "Iteration 24, loss = 38.04391344\n",
      "Iteration 25, loss = 28.73908541\n",
      "Iteration 26, loss = 29.19065348\n",
      "Iteration 27, loss = 24.25823347\n",
      "Iteration 28, loss = 30.58250790\n",
      "Iteration 29, loss = 56.09230353\n",
      "Iteration 30, loss = 50.44054097\n",
      "Iteration 31, loss = 44.28230032\n",
      "Iteration 32, loss = 26.88159659\n",
      "Iteration 33, loss = 39.30628646\n",
      "Iteration 34, loss = 32.37680121\n",
      "Iteration 35, loss = 26.03122846\n",
      "Iteration 36, loss = 23.49718585\n",
      "Iteration 37, loss = 45.37654713\n",
      "Iteration 38, loss = 27.12582474\n",
      "Iteration 39, loss = 48.69252297\n",
      "Iteration 40, loss = 24.87542531\n",
      "Iteration 41, loss = 45.73809905\n",
      "Iteration 42, loss = 20.66584843\n",
      "Iteration 43, loss = 34.91197673\n",
      "Iteration 44, loss = 30.94090751\n",
      "Iteration 45, loss = 32.00481484\n",
      "Iteration 46, loss = 31.08508849\n",
      "Iteration 47, loss = 22.29501435\n",
      "Iteration 48, loss = 33.55103192\n",
      "Iteration 49, loss = 33.55925866\n",
      "Iteration 50, loss = 22.91876625\n",
      "Iteration 51, loss = 23.02204096\n",
      "Iteration 52, loss = 20.37724814\n",
      "Iteration 53, loss = 33.19914828\n",
      "Iteration 54, loss = 20.92142496\n",
      "Iteration 55, loss = 20.14111969\n",
      "Iteration 56, loss = 22.31208610\n",
      "Iteration 57, loss = 20.36891746\n",
      "Iteration 58, loss = 23.94934403\n",
      "Iteration 59, loss = 18.46671276\n",
      "Iteration 60, loss = 19.88108877\n",
      "Iteration 61, loss = 25.89799714\n",
      "Iteration 62, loss = 21.12573811\n",
      "Iteration 63, loss = 28.07218841\n",
      "Iteration 64, loss = 18.84249565\n",
      "Iteration 65, loss = 22.58050605\n",
      "Iteration 66, loss = 19.46047165\n",
      "Iteration 67, loss = 22.15668585\n",
      "Iteration 68, loss = 36.97943694\n",
      "Iteration 69, loss = 17.76770502\n",
      "Iteration 70, loss = 23.99411639\n",
      "Iteration 71, loss = 17.65094367\n",
      "Iteration 72, loss = 19.41725196\n",
      "Iteration 73, loss = 22.29666137\n",
      "Iteration 74, loss = 16.05959108\n",
      "Iteration 75, loss = 17.64690758\n",
      "Iteration 76, loss = 17.91103138\n",
      "Iteration 77, loss = 18.24923662\n",
      "Iteration 78, loss = 16.75631660\n",
      "Iteration 79, loss = 15.65671295\n",
      "Iteration 80, loss = 25.92697536\n",
      "Iteration 81, loss = 17.00893825\n",
      "Iteration 82, loss = 18.37496834\n",
      "Iteration 83, loss = 16.51620797\n",
      "Iteration 84, loss = 15.12610400\n",
      "Iteration 85, loss = 14.91868436\n",
      "Iteration 86, loss = 25.52992700\n",
      "Iteration 87, loss = 20.25858551\n",
      "Iteration 88, loss = 18.70522328\n",
      "Iteration 89, loss = 20.83074196\n",
      "Iteration 90, loss = 29.65600063\n",
      "Iteration 91, loss = 26.82348925\n",
      "Iteration 92, loss = 18.40897527\n",
      "Iteration 93, loss = 18.81370790\n",
      "Iteration 94, loss = 18.30121220\n",
      "Iteration 95, loss = 15.40289154\n",
      "Iteration 96, loss = 16.02316291\n",
      "Iteration 97, loss = 15.11242478\n",
      "Iteration 98, loss = 15.69595802\n",
      "Iteration 99, loss = 15.45233198\n",
      "Iteration 100, loss = 28.32141232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arist\\OneDrive\\Skrivebord\\DSL labs\\DSL_project2\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                                             (&#x27;clf&#x27;,\n",
       "                                              MLPRegressor(learning_rate_init=0.01,\n",
       "                                                           max_iter=100,\n",
       "                                                           n_iter_no_change=50,\n",
       "                                                           random_state=42,\n",
       "                                                           verbose=1))]),\n",
       "                   param_distributions={&#x27;clf__hidden_layer_sizes&#x27;: [(50,),\n",
       "                                                                    (25, 25),\n",
       "                                                                    (15, 10, 10,\n",
       "                                                                     15)]},\n",
       "                   scoring=make_scorer(mean_euclid_dist, greater_is_better=False, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                                             (&#x27;clf&#x27;,\n",
       "                                              MLPRegressor(learning_rate_init=0.01,\n",
       "                                                           max_iter=100,\n",
       "                                                           n_iter_no_change=50,\n",
       "                                                           random_state=42,\n",
       "                                                           verbose=1))]),\n",
       "                   param_distributions={&#x27;clf__hidden_layer_sizes&#x27;: [(50,),\n",
       "                                                                    (25, 25),\n",
       "                                                                    (15, 10, 10,\n",
       "                                                                     15)]},\n",
       "                   scoring=make_scorer(mean_euclid_dist, greater_is_better=False, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MLPRegressor(learning_rate_init=0.01, max_iter=100,\n",
       "                              n_iter_no_change=50, random_state=42,\n",
       "                              verbose=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MLPRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPRegressor.html\">?<span>Documentation for MLPRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MLPRegressor(learning_rate_init=0.01, max_iter=100, n_iter_no_change=50,\n",
       "             random_state=42, verbose=1)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=2,\n",
       "                   estimator=Pipeline(steps=[('scale', StandardScaler()),\n",
       "                                             ('clf',\n",
       "                                              MLPRegressor(learning_rate_init=0.01,\n",
       "                                                           max_iter=100,\n",
       "                                                           n_iter_no_change=50,\n",
       "                                                           random_state=42,\n",
       "                                                           verbose=1))]),\n",
       "                   param_distributions={'clf__hidden_layer_sizes': [(50,),\n",
       "                                                                    (25, 25),\n",
       "                                                                    (15, 10, 10,\n",
       "                                                                     15)]},\n",
       "                   scoring=make_scorer(mean_euclid_dist, greater_is_better=False, response_method='predict'),\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch = RandomizedSearchCV(pipe, param_grid, scoring=score, cv=3, verbose=2)\n",
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf__hidden_layer_sizes</th>\n",
       "      <th>MED</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(15, 10, 10, 15)</td>\n",
       "      <td>-69.671082</td>\n",
       "      <td>66.916625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(50,)</td>\n",
       "      <td>-73.800299</td>\n",
       "      <td>43.318914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(25, 25)</td>\n",
       "      <td>-84.586881</td>\n",
       "      <td>51.188641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clf__hidden_layer_sizes        MED       Time\n",
       "2        (15, 10, 10, 15) -69.671082  66.916625\n",
       "0                   (50,) -73.800299  43.318914\n",
       "1                (25, 25) -84.586881  51.188641"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arist\\AppData\\Local\\Temp\\ipykernel_20084\\3228783991.py:16: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  pd.reset_option('all')\n"
     ]
    }
   ],
   "source": [
    "results = pd.concat([pd.DataFrame(gridsearch.cv_results_[\"params\"]),\n",
    "                     pd.DataFrame(gridsearch.cv_results_[\"mean_test_score\"], columns=[\"MED\"]),\n",
    "                     pd.DataFrame(gridsearch.cv_results_[\"mean_fit_time\"], columns=[\"Time\"])],\n",
    "                     axis=1)\n",
    "df = results.sort_values('MED', ascending=False)\n",
    "\n",
    "# Permanently changes the pandas settings\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    " \n",
    "# All dataframes hereafter reflect these changes.\n",
    "display(df)\n",
    "\n",
    "pd.reset_option('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
